<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DB on Hadoo&#39;s Blog</title>
    <link>https://hanchao666.top/categories/db/</link>
    <description>Recent content in DB on Hadoo&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 Sep 2023 18:56:01 +0800</lastBuildDate><atom:link href="https://hanchao666.top/categories/db/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MySQL三大日志(binlog、redo log和undo log)</title>
      <link>https://hanchao666.top/posts/mysql-binlog-redolog-undolog/</link>
      <pubDate>Thu, 07 Sep 2023 18:56:01 +0800</pubDate>
      
      <guid>https://hanchao666.top/posts/mysql-binlog-redolog-undolog/</guid>
      <description>概述 MySQL 日志 主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志几大类。其中，比较重要的还要属二进制日志 binlog（归档日志）和事务日志 redo log（重做日志）和 undo log（回滚日志）。
下面分别介绍一下这三种日志： redo log（重做日志）、binlog（归档日志）、两阶段提交、undo log （回滚日志）。
redolog redo log（重做日志）是 InnoDB存储引擎独有的，它让 MySQL拥有了崩溃恢复能力。
比如 MySQL 实例挂了或宕机了，重启时，InnoDB存储引擎会使用 redo log恢复数据，保证数据的持久性与完整性。
MySQL 中数据是以页为单位，你查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 Buffer Pool 中。后续的查询都是先从 Buffer Pool 中找，没有命中再去硬盘加载，减少硬盘 IO 开销，提升性能。更新表数据的时候，也是如此，发现 Buffer Pool 里存在要更新的数据，就直接在 Buffer Pool 里更新。然后会把“在某个数据页上做了什么修改”记录到重做日志缓存（redo log buffer）里，接着刷盘到 redo log 文件里。
理想情况，事务一提交就会进行刷盘操作，但实际上，刷盘的时机是根据策略来进行的。
每条 redo 记录由“表空间号+数据页号+偏移量+修改数据长度+具体修改的数据”组成
刷盘时机
InnoDB 存储引擎为 redo log 的刷盘策略提供了 innodb_flush_log_at_trx_commit 参数，它支持三种策略：
0 ：设置为 0 的时候，表示每次事务提交时不进行刷盘操作 1 ：设置为 1 的时候，表示每次事务提交时都将进行刷盘操作（默认值） 2 ：设置为 2 的时候，表示每次事务提交时都只把 redo log buffer 内容写入 page cache innodb_flush_log_at_trx_commit 参数默认为 1 ，也就是说当事务提交时会调用 fsync 对 redo log 进行刷盘</description>
    </item>
    
    <item>
      <title>谈谈数据库如何存储时间</title>
      <link>https://hanchao666.top/posts/how-db-store-time/</link>
      <pubDate>Mon, 18 Apr 2022 18:22:01 +0800</pubDate>
      
      <guid>https://hanchao666.top/posts/how-db-store-time/</guid>
      <description>水一篇短小精悍的文章。
平时开发中不可避免的就是在数据库中进行时间的存储，比如说记录的创建时间、更新时间等等。底层数据结构的选型对于系统来说至关重要，那么下面探索一下这种场景的方法论。
1.不要用字符串存储日期 这种方式有点还是有的，就是简单方便，什么数据都可以丢给字符串，然后直接塞到库里面。但是这种做法主要有下面两个问题：
字符串的占用空间更大 字符串存储的日期效率比较低(逐个字符进行比对)，无法用日期相关的API进行计算和比较 所以还是不要用。
2.Datetime or Timestamp? Datetime 和 Timestamp 是 MySQL 提供的两种比较相似的保存时间的数据类型。他们两者究竟该如何选择呢？
通常是选用的TimeStamp的，下面说一下理由。
理由1 DateTime类型是没有时区信息的(时区无关)，其保存的时间是当前会话所设置的时区对应的时间，这样当时区进行更换时，比如服务器更换地址或者更换客户端连接时区设置的话，就会导致从数据库中度出的时间错误。
而TimeStamp和时区有关。其类型字段的值会随着服务器时区的变化而变化，自动换算成相应的时间，说简单点就是在不用时区，查询到同一条记录时间字段的值是不同的。
例如：
建表 SQL 语句
CREATE TABLE `time_zone_test` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `date_time` datetime DEFAULT NULL, `time_stamp` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 插入数据
INSERT INTO time_zone_test(date_time,time_stamp) VALUES(NOW(),NOW()); 查看数据：
select date_time,time_stamp from time_zone_test; 结果：
+---------------------+---------------------+ | date_time | time_stamp | +---------------------+---------------------+ | 2020-01-11 09:53:32 | 2020-01-11 09:53:32 | +---------------------+---------------------+ 修改对话时区：</description>
    </item>
    
    <item>
      <title>缓存更新的三种模式</title>
      <link>https://hanchao666.top/posts/three-cache-way/</link>
      <pubDate>Sun, 03 Apr 2022 17:36:04 +0800</pubDate>
      
      <guid>https://hanchao666.top/posts/three-cache-way/</guid>
      <description>计算机世界的很多难题都可以使用中间层的思想解决。在一个业务系统中，最耗费性能的通常是最后端的数据库，服务器和数据库的磁盘IO开销，一般都是业务系统最大的性能短板，所以这一部分的性能优化，就显得尤为重要。如果使用中间层的思想解决这个问题，那么加入缓存就是非常经典的落地案例。在数据库的增删改查中，select 通常是最容易出问题的操作，因为绝大多数业务系统基本都是读多写少的，而insert、update、delete由于索引的存在，不太会出现性能问题。下面分别介绍三种常用的缓存设计模式：
1. Cache Aside更新模式 其逻辑如下：
读：如果命中缓存，那么直接返回数据、如果没命中，那么直接去库里面取，成功后放到缓存中 写：直接更新数据库，并令缓存失效 在写操作更新缓存中，Cache Aside使用的是直接令缓存失效，而不是更新缓存，为什么要这么做呢？
考虑在并发写的情况下，A、B都要执行更新操作，A先执行了更新数据库操作，因为两个写操作可能存在数据量差异以及需要进行锁表，可能存在写速度上的不一致，最终出现下面的执行顺序：
A更新数据库 - B更新数据库 - B更新缓存 - A更新缓存
如此一来，那么缓存中就存在脏数据的情况。
那么Cache Aside的这种模式一定是安全的吗？不是的。如果A操作执行了读操作，没有命中缓存，那么去数据库里面读取，这时操作B执行写操作，写成功之后令缓存失效，然后A操作拿到读取到旧数据更新缓存，这种情况下，还是存在脏数据的可能性。其时序图如下：
但是这种情况发生的概率很低，如果发生，需要满足一下三个条件：
读操作读取Cache时，此时Cache刚好失效 写操作执行速度要比读操作执行快 读操作的更新缓存要在写操作删除缓存之后 虽然发生的概率极低，但是不代表问题不存在。如何解决呢？三种方式：
使用2PC(影响速度) 使用Paxos or Raft(增加复杂性) 接受(尽最大可能降低并发时脏数据的概率，并给缓存设置合理的过期时间) 目前FaceBook就是采用了第三种解决方式，虽然牺牲了数据百分之百的一致性，但是换来了系统的高性能，也是一种Trade Off，具体参考：《Scaling Memcache at Facebook》
2. Read/Write Through更新模式 这个模式使用了工具类的思想，对内封装了缓存一致性的复杂度，对外暴露的简单的调用接口，应用层不需要主动实现数据一致性，只需要把缓存和数据库理解为绑定在一起的数据存储服务即可。
具体实现逻辑：
读：当缓存失效时(过期或LRU)，在Cache Aside中，更新缓存的操作由调用方实现，但是在Read Through中缓存服务自己来实现，对调用方来讲，这个过程是透明的。 写：如果没有命中缓存，那么更新数据库；如果命中，那么直接更新缓存，并由缓存服务同步更新数据库。 3. Write Behind Caching更新模式 基本逻辑图：
Write Behind利用了Linux操作系统的Page Cache原理，在更新数据的时候，只更新缓存，然后让缓存来异步的更新数据库，这个过程都是直接操作内存，当异步进行更新数据库时，Write Behind还可以合并对同一数据的批量操作，所以这种模式速度快的飞起，但是却牺牲了数据的强一致性，因为数据都是放在内存中，一旦系统异常被kill，那么会导致数据的丢失，这和Linux系统异常关机，会导致数据丢失是一个道理。同时这个更新模式也具有一定的复杂度，我们需要track哪些内存是被修改过的脏页，并维护起来。在软件设计上，鱼和熊掌不可兼得，总是要作出一些取舍，来设计出符合我们业务场景的、最能接收的&amp;quot;最佳&amp;quot;设计。
4. 其他 目前的数据库缓存基本使用搭建Redis集群的方式实现，一方面是由于Redis自身的强大特性，另一方面，在容器服务上如果放置本地缓存，是行不通的。可能由于本地缓存的机器内存不够大，另外本地缓存由于让容器服务带上了数据属性，服务有了状态，不方便进行水平扩容等管理措施。 缓存时间不宜过长或过短，这个需要我们根据具体的业务场景，来做一个合理的设置。如果缓存时间过短，那么会频繁的从数据存储中检索数据，如果过长，会导致数据长期留存在内存中，浪费资源。 很多缓存系统都使用LRU这种淘汰策略，需要在key-value这样的非顺序存储结构中，维护一个顺序的存储结构，来保证内存排序的优先级。LRU在读写是都是需要加锁的(单线程除外)，这个加锁操作可能会导致更慢的存取时间，需要注意。 爬虫影响 爬虫是无处不在的，爬虫可能会让一些非热点数据，占据我们的内存，这会降低业务系统热点数据的缓存命中率。一般这种情况，我们可能需要加上爬虫保护机制，或者是引导爬虫访问专门的api，做一个分流，对业务系统是一套缓存机制，对爬虫是一套机制。 真的要加缓存嘛 任何一个新技术组件的引入，都会增加系统整体的复杂度。尽管他能够给我们带来一定的收益，但是随着而来的也会带来隐患。拿缓存来说，他固然可以提高业务系统的存取速率与响应时间，但是带来了维护缓存一致性的复杂。得到的是性能提升，失去的是系统的强一致性。所以一定要做好需求调研，看是否需要引入。 </description>
    </item>
    
    <item>
      <title>一条SQL执行很慢的原因</title>
      <link>https://hanchao666.top/posts/slow-sql-reason/</link>
      <pubDate>Sun, 07 Nov 2021 17:22:19 +0800</pubDate>
      
      <guid>https://hanchao666.top/posts/slow-sql-reason/</guid>
      <description>分情况讨论：
大多数情况下是正常的，但是偶尔会很慢 数据量不变，这条语句一直就很慢 一.偶尔很慢 1.数据库正在刷新脏页 当我们对数据库进行更新时，并没有直接修改磁盘文件，而是将内存数据页进行更新，然后再将更新的记录追加到redo log日志中，等到一定的时机，再将内存数据页刷新到磁盘数据页中去
当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。
上面说的是一定的时机刷新脏页，那么是什么时机呢？
redo log写满了： 如果数据库一直很忙，更新操作又很频繁，那么这时候日志文件满了之后，就要进行类似于JVM中STW的操作，暂停一切更新操作，来全力的执行刷新脏页操作，这个过程更新操作性能下降，不，是消失为0，所以就会导致sql语句执行突然变慢，类似于抖动的感觉，下一次执行就很慢再出现这种情况了
内存不够用了： 当需要新的内存页时，要申请内存，但是这时出现内存不足的情况，就会通过相应的页面置换算法淘汰掉一部分页面，如果被淘汰的是干净页，那没啥说的，直接释放，如果是脏页还要进行向磁盘数据页中刷新脏页的操作
InnoDB用缓冲池buffer pool来管理内存，缓冲池中的内存页有三种状态：
还没使用 使用了并且是干净页 使用了并且是脏页 InnoDB的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；当如果是脏页，就必须先讲脏页刷盘，变成干净页后才能复用。所以刷脏页是常态。 mysql认为系统空闲的时候
mysql正常关闭的时候
2.拿不到锁 这种情况在并发访问数据库的时候也会发生，当我的sql语句要访问的表或者表的某些行加上了表级锁或者行级锁，并且其他人正在占用锁的时候，那么就只能慢慢等待人家释放锁了
在mysql中可以使用 show processlist查看相应占用者
二.一直很慢 1.没用到索引 没用到索引还是两种情况：
没有建立索引：这种情况没啥可说的，每一次都是全表扫描 有索引但是没用上：这就需要考虑索引失效的问题，索引失效与优化详解 2.数据库自己选错索引 这个概念还是第一次听到，这里有一篇分析的非常好的文章，MySQL为什么有时候会选错索引？，可以仔细研读一下
三.总结 一个 SQL 执行的很慢，我们要分两种情况讨论：
1、大多数情况下很正常，偶尔很慢，则有如下原因
(1)、数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。
(2)、执行的时候，遇到锁，如表锁、行锁。
2、这条 SQL 语句一直执行的很慢，则有如下原因。
(1)、没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引。
(2)、数据库选错了索引。
关于数据库选错索引需要着重理解一下，这里面是和mysql的优化器的统计工作相关的，里面还涉及到了索引的区分度等概念，值得重视起来</description>
    </item>
    
  </channel>
</rss>
