<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Midware on 知行XYZ</title>
    <link>https://hanchao666.top/categories/midware/</link>
    <description>Recent content in Midware on 知行XYZ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 01 Mar 2022 18:18:40 +0800</lastBuildDate><atom:link href="https://hanchao666.top/categories/midware/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kafka为什么性能这么牛？</title>
      <link>https://hanchao666.top/posts/why-kafka-niubility/</link>
      <pubDate>Tue, 01 Mar 2022 18:18:40 +0800</pubDate>
      
      <guid>https://hanchao666.top/posts/why-kafka-niubility/</guid>
      <description>Apache Kafka是一个高性能的消息队列，在目前众多消息队列产品中，Kafka的性能绝对是第一梯队的，且Kafka也是大数据生态的组件，背书很硬。下面来看一下，Kafka是如何达到高性能表现的。
全异步化的线程模型
简单的说，异步思想就是当我们执行一项比较耗时的操作，不去等待操作结束，而是给这个操作一个命令：当操作完成后，接下来去执行什么。
使用异步编程模型，虽然不能加快程序本身的速度，但可以减少或者避免线程等待，只用很少的线程就可以达到超高的吞吐能力。异步相对同步，实现的复杂度要更大，代码的可读性和可维护性都会下降，而Kafka作为消息队列，业务逻辑简单并且需要超高的吞吐量，所以场景匹配。
高性能的异步网络传输
传统的同步网络IO，一般采用的都是一个线程对应一个Channel接收数据，很难支持高并发和高吞吐量，而异步网络可以用单个线程同时管理多个连接，实现多路复用。
自定义序列化、反序列化协议
进程之间通过网络传输结构化数据，需要通过序列化和反序列化来实现结构化数据和二进制数据的双向转换。大多数情况下，选择一个高性能的通用序列化框架都可以满足需求，但是Kafka为了实现超高的性能，自定义了专用的序列化方法，来提高序列化性能，节省传输流量。
自定义传输协议
自定义私有应用层传输协议
批处理
批处理是一种非常有效的提升系统吞吐量的方法。在Kafka内部，消息都是以批为单位处理的。
Kafka给发送端提供的接口虽然每次只能发送一条消息，但是实际上，Kafka不会立即把这条消息发送出去，而是先在内存中缓存起来，然后选择合适的时机把缓存中的消息组成一批，一次性发给Broker，采用了异步批量发送的机制，攒一波一起发。
在Kafka的服务端，也就是Broker这一端，不会把一批消息再还原成多条消息一条一条处理，在Broker整个处理流程中，无论是写入磁盘、从磁盘读出来、还是复制到其他副本这些流程中，批消息都不会被解开，一直是作为一条“批消息”来处理。在消费时，消息同样是以批为单位传递，Consumer从Broker拉到一批消息后，在客户端把批消息解开，再一条一条的交给用户代码处理。比如说，你在客户端发送 30 条消息，在业务程序看来，是发送了 30 条消息，而对于 Kafka 的 Broker 来说，它其实就是处理了 1 条包含 30 条消息的“批消息”而已。显然处理 1 次请求要比处理 30 次请求要快得多。
构建批消息和解开批消息分别在发送端和消费端的客户端完成，不仅减轻了Broker的压力，最重要的是减少了Broker处理请求的次数，提升了总体的处理能力。
使用顺序读写提升磁盘IO性能
对于磁盘来说，顺序读写的性能要远远好于随机读写。操作系统每次从磁盘读写数据的是够，需要先寻址，也就是先要找到数据在磁盘上的物理位置，然后再进行数据读写。如果是机械硬盘，这个寻址需要比较长的时间，因为他要移动磁头，这是一个机械运动。顺序读写相比随机读写省去了大部分的寻址时间，它只要寻址一次，就可以连续读写下去，性能要比随机读写好的多。
在kafka中，对于每个分区，他把从Producer收到的消息，顺序的写入对应的Log文件中，一个文件写满了，就开启一个新的文件这样顺序写下去。消费的时候，也就是从某个全局的位置开始，也就是某一个Log文件中的某个位置开始，顺序的把消息读出来。Kafka充分的利用了顺序读写的这个特性，极大的提升了Kafka在使用磁盘时的IO性能。
利用PageCache加速消息读写
PageCache就是操作系统在内存中给磁盘上的文件建立的缓存，在调用系统的API读取文件的时候，并不会直接去读写磁盘上的文件，应用程序实际操作的是PageCache，也就是文件在内存中缓存的副本。
应用程序在写入文件的时候，操作系统会先把数据写入到内存中的PageCache，然后再一批一批的写到磁盘上。读取文件的时候，也是从PageCache来读取数据，这个时候有两种可能情况。
PageCache中有数据。直接读取，节省了从磁盘读取数据的时间 PageCache没有数据。操作系统引发缺页中断，应用程序的读取线程会被阻塞，操作系统把数据从文件中复制到PageCache，然后应用程序再从PageCache中继续把数据读出来，这时会进行真正的磁盘IO，读取过程相对较慢。 用户的应用程序在使用完某块PageCache后，操作系统并不会立刻就清除这个PageCache，而是尽可能的利用空闲的物理内存保存这些PageCache，除非系统内存不够用，操作系统才会清掉一部分PageCache，清理策略一般是LRU：优先保留最近一段时间最常使用的那些PageCache。
Kafka在读取消息文件的时候，充分契合了PageCache的特性。一般来说，消息刚刚写到服务端就会被消费，按照LRU的清除策略，读取的时候，对于这种刚刚写入的PageCache，命中的几率会非常高。也就是说，在大部分情况下，消费端读取消息都能命中PageCache，带来的好处有两个：一个一个是读取的速度非常快，另外就是给写入消息让出了磁盘IO资源，间接的提升了写入性能。
零拷贝技术
在服务端，处理消息的大致逻辑是这样：
在文件中找到消息数据，读到内存 把消息通过网络发给客户端 这个过程中，数据会经过两次或者三次复制：
1.从文件复制数据到PageCache，如果命中PageCache，这一步可以省略。
2.从PageCache复制到应用程序的内存空间，也就是我们可以操作的对象所在的内存。
3.从应用程序的内存空间复制到Socket的缓冲区，这个过程就是我们调用网络应用框架的API发送数据的过程。
Kafka使用零拷贝技术可以把这个复制次数减少一次，上面的2、3步骤就可以复制合并成一次复制。直接从PageCache中把数据复制到Socket缓冲区中，这样不仅减少一次数据复制，更重要的是，由于不用把数据复制到用户内存空间，DMA控制器可以直接完成数据复制，不需要CPU参与，速度更快。</description>
    </item>
    
    <item>
      <title>使用消息队列要考虑的四个问题</title>
      <link>https://hanchao666.top/posts/4-q-when-use-mq/</link>
      <pubDate>Sun, 17 Oct 2021 17:45:58 +0800</pubDate>
      
      <guid>https://hanchao666.top/posts/4-q-when-use-mq/</guid>
      <description>0.如何进行消息队列的选型 1.消息队列的选择 开源：出现问题可以查看源码解决，而不是被动的等待新版本发布 社区活跃：其他人也会遇到相同的使用问题 生态环境：kafka的生态环境和大数据环境完全匹配兼容 基本特性：作为消息队列，要保证不丢消息，高可用，并且性能也要可观，能够满足绝大多数场景的性能需求 2.可供选择的消息队列 目前没有一款消息队列能够做到一统天下，这一块还是比较多元化的， 需要我们熟悉理解每个消息队列的特性，然后根据具体的业务场景，选用合适的消息队列
RabbitMQ 关键词就是轻量级，使用Erlang语言编写，支持AMQP协议
一个特色就是在生产者和队列之前加入了Exchange模块进行路由配置，路由规则是比较灵活的，可以手动进行配置
缺点：
1.对消息积压的支持并不好，他的设计理念认为消息队列就是一个通道，当消息积压时，性能会急剧下降
2.性能不如其他的消息队列，正常情况下，普通的业务场景是可以满足的，但是当系统对性能要求比较高的时候，就不要选择这个了
3.这玩意是使用Erlang语言开发的，比较冷门，不容易进行二次开发
RocketMQ 阿里爸爸开发出来的消息队列，经历了世界上最大并发量、吞吐量的双十一的考验，可见是多么牛逼
使用Java语言写的，因为阿里主要搞电商，RcoketMQ对在线业务的时延响应做了很多优化
RocketMQ方方面面都不错如果非要挑出什么缺点，那么就是和kafka相比，生态还不够好
kafka 消息队列这一块扛把子的老大哥，之前刚出来的时候是为了解决海量日志的，那时候还不能保证丢消息，但是发展到现在已经可以确保消息不丢了，整体设计采用大量的异步和批处理的思想，在所有消息队列里面性能算是最好的，但是正是因为kafka采用异步、批处理的思想，所以对于一些实时性比较高的在线业务来讲，时延会比较高，因为kafka的很多地方都是攒够一波一起发这样做的，如果消息不是那么多的时候，时延就会比较大
如果消息队列不是业务系统的核心，我们对消息队列也没什么特别的要求，那么选择Rabbit就可以了，他就是为了开箱即用的特点诞生的，轻量级，也很OK
如果业务系统对时延要求比较高，吞吐量也比较大的话，那么选用RocketMQ或者JMQ吧，不仅可以保证低时延，也可以保证金融级别的稳定
如果需要处理海量的数据，或者说系统中使用了大数据生态系统中的东西，那么就直接选用kafka， 性能好，生态好
不过我的了解是，目前很多的系统都是采用了不止一种消息队列，而是采用组合的方式，例如：RocketMQ+Kafka，分别用于在线业务和日志，这样就可以兼顾两个的优点，随之带来的问题就是开发维护成本变高了
1.如何保证消息不丢 一个消息队列立足之根本，就是要保证消息不丢失，那么具体是如何实现的呢？哪些地方可能会导致消息丢失呢？
无非就是以下三个阶段可能会导致消息丢失：
生产阶段 存储阶段 消费阶段 现在市面上的主流消息队列都可以保证消息不丢，不管是网络出现问题，还是节点出现宕机，都可以保证消息不丢，很多情况下都是开发者使用不当导致的
下面分别看一下这三个阶段，是如何做到不丢消息的：
生产阶段： 生产阶段普遍采用的是请求确认机制，生产者发出消息之后，当Broker收到消息之后，会返回一个确认响应，如果生产者收到这个响应，那么说明发送成功， 如果没收到，就会进行超时重试，这里面会涉及到一个问题，为什么生产者没有收到响应？可能是两个原因：1.因为网络问题，消息确实在传输过程中丢了，这种情况下进行重试，可以保证Broker收到消息，2.Broker收到了消息，但是响应因为网络问题丢了，这个时候生产者还是会进行重发，这就会导致主题上面可能会有重复消息，这也是我们接下来需要考虑的一个问题，消息重复了怎么办？
存储阶段： 存储阶段还是分两种情况，如果Broker是单机的，那么需要保证消息落盘之后，再返回确认响应，这时候消息已经在磁盘中进行了持久化，就不会丢，如果Broker是集群形式的，那么可以通过配置，当消息在其他Broker节点上进行复制成功之后，再返回确认响应，当一个Broker宕机之后，其他的就可以进行补上 消费阶段： 消费阶段和生产类似，也是通过确认机制来保证消息的不丢，当消费者客户端拿到消息之后，不要立即返回确认响应，而是在完成所有消费业务逻辑之后，再发送确认响应，这样如果在消费消息阶段失败了，那么下一次消费时可以继续消费上一次消费位置的消息，这里还有一种情况：如果消费者发出的消费确认响应丢了怎么办？这里还会涉及到重复消息的问题，后面我们一起讨论 一个合格的消息队列，上面的三个阶段都是可以严格保证消息不丢的，实际上我们在使用消息队列的时候，丢失消息的原因大多数是消费位置的不当导致的，因为目前大多数消息队列都是基于发布订阅模型的，每个消息都可以被多个消费者组消费，每个消费者组是互不影响的，而一个消费者组中的每个消费者是存在竞争关系的，当主题中的一个消息被一个消费者组消费完成之后，不能立即将消息删除，因为其他消费者组后面可能还会进行消费，这是我们需要为每个消费者组维持一个消费位置的变量
2.消息重复怎么办 首先明确一个立场：不管是在哪一种消息队列中，都可能存在重复消息的情况。
之前的问题中已经埋下了一个伏笔，也就是在生产者如果可能会将重复的消息发送到消息队列中，所有的消息队列都是At least Once级别的，之前就听说过Kafka可以保证Exactly Once级别，但是玥哥也是说了，这主要是为了配合流计算领域的实现，在消息的生产消费关系中，消息队列中 也是可能存在重复消息的！后面会单独写一篇文章，说一下事务和Exactly Once在流计算中是怎么搞的，既然消息队列中存在重复消息这件事情已经成为了既定的事实，那么我们只能通过在消费端的业务中实现幂等性来保证了，这样就可以满足：**At least once + 幂等消费 = Exactly once
下面是几种实现幂等性的方法：
利用数据库的唯一性实现 大概的思路就是利用数据库的主键的特性，当消息重复时，消费者在数据库表中可以检测到主键冲突异常，这样就可以不用进行接下来的重复消费
设置相关判定条件 比如，“将账户 X 的余额增加 100 元”这个操作并不满足幂等性，我们可以把这个操作加上一个前置条件，变为：“如果账户 X 当前的余额为 500 元，将余额加 100 元”，这个操作就具备了幂等性。对应到消息队列中的使用时，可以在发消息时在消息体中带上当前的余额，在消费的时候进行判断数据库中，当前余额是否与消息中的余额相等，只有相等才执行变更操作。</description>
    </item>
    
  </channel>
</rss>
