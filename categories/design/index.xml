<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Design on 知行XYZ</title>
    <link>https://hanchao666.top/categories/design/</link>
    <description>Recent content in Design on 知行XYZ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Sep 2023 17:55:14 +0800</lastBuildDate><atom:link href="https://hanchao666.top/categories/design/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>大数据量系统去重方案</title>
      <link>https://hanchao666.top/posts/big-data-deduplicate/</link>
      <pubDate>Tue, 12 Sep 2023 17:55:14 +0800</pubDate>
      
      <guid>https://hanchao666.top/posts/big-data-deduplicate/</guid>
      <description>0.概述 大数据去重是一个经典的业务场景，包括统计网站登录用户的UV、网页爬虫对URL去重等，下面对其解决方案进行调研学习。
可以将去重情景分成几个维度：
实时还是离线 是否要求绝对精准 单进程还是分布式 下面分别介绍几种常见的去重方式
1.方案 1.1 HashMap&amp;mdash;&amp;gt;BitMap&amp;mdash;&amp;gt;Roaring BitMap 最原始的方案就是使用HashMap，在业务代码中经常使用HashMap来保存key-value的映射关系，当要判断一个key是否已经存在时，使用map.get()获取对应的value来进行判断。
随着数据量的增大，这种数据结构就会暴露出弊端。加入我们创建的hashMap为Intege类型，那么存储一个元素需要使用4个Btye的空间，如果我们存在2亿个元素，那么机器的内存肯定是扛不住的。及时是使用Byte类型的hashMap，2亿个元素也需要(2亿 * 1 / 1024 / 1024)M的内存空间。
使用HashMap每次存储的value就是一个boolean类型的value，使用Byte这样的空间显的有些浪费，使用0 1就可以解决，在计算机世界里面，最小的表示0 1的存储单元是bit，1 byte = 8 bit，这样我们就可以把存储空间进行压缩。
BitMap的最大占用空间由元素中最大的数值决定，如果待判断元素分布的极为不均匀，例如[1,1000000]，那么BitMap也需要开辟出1000000这样大的存储空间，有点浪费。虽然bit已经是可以使用的最小单位了，但还是可以采用压缩算法，及Roaring BitMap(压缩位图)，相比于BitMap，这种结构在性能和空间利用率上有了显著的提升。
压缩位图的主要流程：
我们将 32-bit 的范围 ([0, n)) 划分为 2^16 个桶，每一个桶有一个 Container 来存放一个数值的低16位； 在存储和查询数值的时候，我们将一个数值 k 划分为高 16 位(k % 2^16)和低 16 位(k mod 2^16)，取高 16 位找到对应的桶，然后在低 16 位存放在相应的 Container 中； 容器的话， RBM 使用两种容器结构： Array Container 和 Bitmap Container。Array Container 存放稀疏的数据，Bitmap Container 存放稠密的数据。即，若一个 Container 里面的 Integer 数量小于 4096，就用 Short 类型的有序数组来存储值。若大于 4096，就用 Bitmap 来存储值。 举个例子：</description>
    </item>
    
    <item>
      <title>汤师爷翻译一下，什么TMD叫反向代理！</title>
      <link>https://hanchao666.top/posts/fucking-reverse-proxy/</link>
      <pubDate>Thu, 13 Apr 2023 14:18:04 +0800</pubDate>
      
      <guid>https://hanchao666.top/posts/fucking-reverse-proxy/</guid>
      <description>对于反向代理这个概念理解的一直不是很透彻，今天让汤师爷给咱翻译一下：
正文开始：
首先看一下，什么是正向代理。
假如说我想买一个iphone14 pro，但是没钱，于是决定去找东哥借钱。可想而知，根本行不通。情急之下回头一想，想起了大学同学小杨是东哥的宿迁老乡，于是我就找到小杨，委托他帮我去找东哥借钱，最后事成了。不过东哥并不知道这笔钱是借给我的，东哥是借给小杨的，最后小杨把钱交给我。这里的小杨就扮演了一个非常关键的角色，就是代理，也可以说是正向代理，小杨替我借钱这件事，这个行为东哥不知道真正借钱的人是谁，这点很关键。
回到计算机世界，其实我们常说的代理就是正向代理，它隐藏了真实的请求客户端，服务端不知道真正的客户端是谁，客户端请求的服务都被代理服务器代理来请求，这也就是科学上网代理服务器的工程原理，由于GFW的存在，国内使用浏览器访问Google时，会被残忍的block，有多少包丢多少包，于是可以在国外(不是朝鲜就行qaq)搭建一台代理服务器，让代理去帮助请求Google，代理把请求返回的相应结构再返回给我。
咳咳，反正博客没人看就多说点，代理服务器推荐搬瓦工CN2 GIA，线路稳定速度快，赶在黑色星期五可以便宜很多，咳咳，，
反向代理
还是举个例子。
在我们拨打10086客服电话的时候，一个地区的10086客服可能有很多个，但我们并不关心电话那头的是哪一个，可能是GG，也可能是MM，但我们关心的是问题能不能得到专业的解答，只要拨通了10086的总机号码，电话那头总有人回答，这里的10086总机号码就是反向代理。
回到计算机世界，反向代理隐藏了真实的服务端，当我们请求www.baidu.com的时候，就像拨打10086一样，背后可能有成千上万台服务器为我们服务，但具体是哪一台，我们不知道，也不关心。我们只需要把请求发给反向代理服务器，他会帮我们把请求转发到真实的服务器那里去。Nginx就是一个很经典的反向代理服务器，可以用来做负载均衡。
最后一句话总结：
两者的区别在于代理的对象不一样，正向代理代理的对象是客户端，反向代理代理的对象是服务端。</description>
    </item>
    
    <item>
      <title>【代码精进之路】- 重构&amp;单元测试</title>
      <link>https://hanchao666.top/posts/refactor-unit-test/</link>
      <pubDate>Tue, 13 Dec 2022 14:08:07 +0800</pubDate>
      
      <guid>https://hanchao666.top/posts/refactor-unit-test/</guid>
      <description>博客开了一个新的菜单，名为【代码精进之路】，主要用于记录学习与实践过程中关于代码质量的思考与经验总结。
本篇文章题目较大，后续会不断进行内容的补充完善，文章内容主要出自笔者本人重构项目的思考总结，以及极客时间《设计模式之美》的学习内容。
一 概述 什么是重构？ 软件设计大师、《重构》作者Martin Fowler如此定义：”重构是一种对软件内部结构的改善，目的是在不改变软件的可见行为的情况下，使其更容易理解，修改成本更低。“
为什么要重构？ 根据熵增定律，所有事物都在向着无规律、无序和混乱发展，例如屋子不收拾会变乱、手机会越来越卡、耳机线会变凌乱&amp;hellip;&amp;hellip;同样的，代码质量也逃不过。项目在演进，随着需求的增多，代码在不停的堆砌，同时也在朝着混乱的方向发展，如果没有人为代码质量负责，那么量变引起质变，代码腐败到维护成本甚至会高过重新开发一套新代码的成本，这会影响到项目的迭代与交付效率，往大了说，在之前国内互联网圈地跑马阶段，迭代交付的慢就会错过商机，所以，重构是一个研发团队保持稳定高效输出的有力手段。
重构无法避免。优秀的代码或架构绝不是一开始就设计好的，而是演进出来的。我们无法100%遇见未来的需求，也没有足够的精力、时间、资源为遥远的未来买单，所以随着系统的演进，我们要接受重构是一个常态化行为。
什么时候重构？ 持续重构。
这是一种可持续、可演进的方式，这要求我们时刻具有持续重构意识，才能避免开发初期就进行过度设计而追求完美、避免代码维护过程中质量的下降，可以在日常迭代开发中掺入”小动作“，例如在修改、添加某个功能代码的时候，可以顺手把不符合编码规范、不好的设计重构一下，把它和单元测试、CodeReview一样，作为一种开发习惯。
如何重构？ 按照规模，重构可以笼统的分为大型重构和小型重构，
对于大型重构，往往涉及的模块、代码较多，很可能会出现越改越多、越改越乱的情况，另外在如今迭代周期普遍较为紧张的情况下，也很难找出一整块完整的时间来进行整个项目的重构。
一个建议就是大型重构一定要提前做好完善的重构计划，有条不紊的分阶段进行，每个阶段完成一小部分代码的重构，然后提交、测试、运行，发现没问题后，再继续进行下一阶段，尽量保证代码仓库中的代码一直处于可运行、逻辑正确的状态。每个阶段都要控制好重构的影响范围以及持续时间，小步快走的方式很重要！
而小规模层次的重构，因为影响范围小，改动耗时短，可以随时穿插着做。
二 重构的技术保障手段-单元测试 ！！！单元测试！！！
主观因素：重构开发者的技术实力 客观因素：科学化技术手段 从主观上来看，需要开发者对所重构的业务和代码要有足够的了解，也需要开发者技术够硬，能hold的住，这没的说。
从客观上来看，最可落地执行、最有效的保证重构不出错的手段，就是单元测试。当重构完成之后，如果新的代码仍然能够通过单元测试，那就说明代码原有逻辑的正确性未被破坏，原有的外部可见行为没变。
下面来主要探讨一下【单元测试】那些事。
单元测试的测试对象是类或函数，用来测试一个类或函数是否都按预期的逻辑执行，由程序员自己来书写以验证自己写的代码的正确性。
单元测试可能会被很多开发团队或工程师忽略，笔者以前同样认为编写并维护单元测试是一件”没必要“的事，然而被现实给上了一课，测试以及用户反馈的一个个bug，绝大多数都是由于代码的方法中的”小问题“导致的，这些问题或者是由于粗心笔误、或者是由于修改后未及时回归，所以说，做好测试的第一步也是最重要的一步就是：要重视单元测试。搞好单元测试，Bug Free不是梦！
除了让我们及时有效的以fail-fast的方式发现代码逻辑问题，单测也能够帮助我们发现设计上的问题，如果你垫的单元测试写起来很吃力，那往往意味着代码设计的不够合理，例如第三方依赖mock不掉、大量使用静态函数或全局变量、代码高度耦合等，代码的可测试性也是衡量代码质量的重要参考因素哦。
另外在我们刚刚接触一个新的项目时，如学习某开源项目，那么推荐的一个方式就是从单测入手，阅读单测可以帮助我们快速的熟悉代码，单元测试一般是一个独立的小功能，好的单测也是见名知意的，借助于此我们可以不再像无头苍蝇一样寻找代码的逻辑链路，可以更省力的知道代码实现了什么功能。
不要觉得有了测试团队，写单测就是浪费时间，现在很多公司的开发模式还仍然是写好代码直接提交，然后丢给黑盒测试拼命的测，测出问题就反馈给开发团队修改，测不出的问题就留在线上出问题了再修复，作为一名有追求的开发者，我们要对自己写的代码负责。
三 单元测试如何做 上述两节较为理论化，下面以一个实际的案例来说明。
代码如下所示，其中Transaction是一个简化后的电商系统交易类，用来记录每笔订单交易的情况。Transaction中的execute()负责执行转账操作，将钱从买家的钱包转到卖家的钱包中。真正的转账操作是WallRpcService的RPC服务来完成的。除此以外，代码中还涉及一个分布式锁DistributedLock单例类，用来避免Tracnsaction并发执行，导致用户的钱被重复转出。
针对核心逻辑execute()方法，设计出以下6个测试用例：
设计完测试用例，当我们将他们落实到具体的代码实现时，却有很多不顺利的地方，以第一个测试用例为例，其代码实现为：
execute()函数的执行依赖两个外部服务，一个是RedisDistributedLock，一个是WalletRpcService，导致这个用例存在以下问题：
这个方法对于两个外部服务是强依赖的，如果这两个服务没有提供线下测试环境，我们可能需要自己搭建。 即使RPC服务有线下测试环境，但如果服务提供者是另外一个团队维护，我们输入正确的入参，结果也不一定返回成功，即RPC的对端也可能是不可靠的，这需要联调。 Redis、RPC依赖网络通信，耗时可能比较长，对单测的执行性能会有影响。 网络的中断、超时、Redis、RPC服务的不可用，都需要考虑。 而单元测试的目的，是为了测试程序员自己编写的代码逻辑是否正确，并非是端到端的集成测试，无需验证所依赖的外部系统的逻辑正确性。所以，我们需要将被测代码与外部系统依赖解耦，采用的方式就是mock。所谓mock就是以假乱真，用mock的服务输出我们想要的数据。
mock的方式主要有两种，框架mock和手动mock。框架mock例如@Mokito，可以简化代码的编写，这里演示一下使用手动mock的方式。
通过继承WalletrpcService类，并且重写其中的moveMoney()函数的方式来实现mock，使其返回我们任意想要的数据，而不进行真正的网络通信。
接下来使用依赖注入的方式优化一下execute()函数的可测试性，因为WalletRpcService是通过new(0的方式创建的，我们无法对其实现进行替换，可以借助依赖注入这个神器，将WalletrpcService对象的创建反转给上层逻辑，在外部创建好之后，再注入到Transaction中，如下所示：
然后在单元测试中WalletRpcService实现类进行替换，
接下来看一下RedisDistributedLock，这家伙更棘手，因为它是一个单例类，相当于一个全局变量，我们无法通过继承并重写的方式mock，也无法通过依赖注入的方式来替换。
如果RedisDistributedLock是我们自己维护的，可以将其实现修改为非静态单例类的模式，或抽出一个接口，比如IDistributedLock，让RedisDistributedLock实现这个接口，我们也就可以通过依赖注入的方式对其进行替换，可是如果这个类不是我们自己维护的，怎么办？
我们可以对上锁这部分逻辑重新封装一下，如下：
代码重构后，使用如下的单元测试代码，即可mock掉外部依赖，测试我们自己的代码逻辑了！
加下来再看一个测试用例3：交易已过期(createTimeStamp超过14天)，交易状态设置为EXPIRED，返回false。写出的单测代码如下：
看起来没啥问题，把时间戳设置为14天前，transaction一定处于过期状态，但是如果createTimeStamp没有暴露set方法呢？例如createTimeStamp的业务定义是在交易生成时自动获取的系统时间，不应该放开修改权限那怎么测？
对于时间和随机函数等这种”未决行为“，一般的处理方式是将未决行为逻辑进行重新封装，将是否交易过期的逻辑封装到isExpired()函数即可，代码如下：
针对重构之后的代码，新的测试用例代码如下：
破坏代码可测试性的行为 未决行为 未决行为逻辑即代码的输出是随机的或者是不确定的，比如跟时间、随机数有关的代码，一个有效的解决方法就是封装不确定性。
全局变量 全局变量是一种面向过程的编码风格，对代码的可测试性非常不友好，因为每个测试用例都可以对全局变量进行修改导致测试用例之间的数据耦合。
静态方法 静态方法也是一种面向过程的编码风格，这也会影响代码的可测试性，静态方法不容易mock。
复杂继承 如果父类需要mock某个依赖对象才能进行单元测试，那所有的子类、孙子类在编写单测的时候，都需要mock这个依赖对象，如果对于层次很深、结构复杂的继承关系，那么越底层的子类需要mock的对象可能就会越多，麻烦的很。
所以推荐尽可能的使用组合而非继承来组织类之间的关系，类之间的结构层次比较扁平，在编写单元测试的时候只需要mock类所组合依赖的对象即可。
四 大型重构之解耦 为什么要解耦</description>
    </item>
    
    <item>
      <title>对于应用架构的胡思乱想</title>
      <link>https://hanchao666.top/posts/think-about-ddd/</link>
      <pubDate>Fri, 03 Jun 2022 18:34:08 +0800</pubDate>
      
      <guid>https://hanchao666.top/posts/think-about-ddd/</guid>
      <description>应用架构，指软件系统中固定不变的代码结构、设计模式、规范和组件间的通信方式。如今在业务研发时往往会更关注宏观上的架构，而忽略了应用内部的架构设计。个人觉得应用内部架构存在更多的细节，也更能体现程序员的功力所在。
基于controller、service、dao进行分层的开发模式在现在的应用架构中占据主流，但究其本质是在使用面向对象的语言，写着面向过程的方法。面向过程的好处是符合我们大脑的思考方式，实现起来简单快捷，并且在业务系统发展初期从0到1的过程，为了业务的抢占以及减少试错成本，是非常实用的。但是从长远来看，传统MVC的service代码无复用性，也不具备比较好的可维护性，这里的可维护性包括外部依赖的影响、新功能扩展以及可测试性等。在软件开发领域，每个service中面向过程的方法都叫做“事务脚本编程”，而在应用架构中，我们需要保证系统能够快速平稳的进行迭代，保证整体的加速度平稳，而传统MVC一旦面临较大的改动，由于存在外部依赖严重等情况，就可能面临着整体重构的风险，这也就是为什么如今项目在发展过程中开发周期逐渐变长的原因，所以作为有追求的开发者，我们应该探索一套高质量的业务响应模型，来尽可能的减少系统腐败的可能性。
在传统的开发模式中，我们最大的问题就是视角被底层数据存储系统束缚，因为我们太重视数据了，每个业务系统其实只在做两件事情：计算数据、存储数据。数据是企业的核心资产，所以我们一般从数据库建模开始，来设计一个业务系统。从这个角度出发，其实我们的应用层代码也不过是具备灵活自定义属性的数据库事务脚本，可对于业务系统来讲，不管是2B还是2C，业务需求的不确定性是其基本特征，在后续的需求迭代中，如果加入了新的需求，我们可能就会面临着之前的事务脚本不能复用，我们还需要更改底层存储结构，可能需要维护两套事务脚本，甚至整体重构，这非常可怕。每次我们的系统都是从0到1开始，有多可怕，就像我们玩一个游戏没有存档功能一样，每次都从头开始的话，我们能受得了吗？对于提倡降本提交的资本家来说，能受得了吗？所以需要变革。
我们之前的关注点失焦了，作为业务系统，其第一关注点应该是业务模型，不能被外部所影响，这里的外部包括客户端形态、外部依赖稳定性以及数据存储组件，都不应该影响我们的业务模型。以业务模型为核心结构，所有的客户端调用、数据持久化、中间件其实都是系统的IO外围，在业务模型的最外层可以增加适配层，来对抗外部环境的变化，下面来一张大师的架构图：
这种以业务模型为核心驱动的开发模式即DDD(领域驱动设计)，DDD不是一个专门的架构，而是任何传统代码在模型划分清晰、充分落实设计原则之后的必然形态。
谈一下DDD的一些概念。DDD会根据实际的业务场景进行建模，不考虑非业务相关的元素，每个Entity都应一个业务实体，Repository负责实体的持久化，而具体的持久化方式是基于相应的实现类，假如我们采用了常用Mybatis，只需实现Repository接口即可，在实现类里面进行Entity到DO的封装转化，并调用DAO进行真正的存储。一旦ORM框架发生变更或底层数据结构发生改变，那么替换为其他实现类即可。
传统开发的第一步是数据库建模，而DDD中需要进行领域建模。首先进行时事件风暴，根据一些业务操作和行为找出实体和值对象。实体和值对象是基础的领域对象，实体一般对应业务对象，它具有业务属性和业务行为；而值对象主要是属性集合，对实体的状态和特征进行描述。但实体和值对象都是个体化的对象，表现出来的是个体的能力。而业务是整体性的，每个实体相当于社会上的一个个人，但社会上都是以组织的形式存在的，例如一个班级、一个公司，所以实体也是需要合作的。所以出现了聚合的概念，聚合由业务和逻辑紧密关联的实体和值对象组成，是数据修改和持久化的基本单元，可以把每个聚合类比为k8s中的pod，属于逻辑分组范畴。
聚合有聚合根和限界上下文，这个边界根据业务单一职责和高内聚原则，聚合之间的边界是松耦合的，所以根据聚合设计出来的系统是高内聚低耦合的。聚合在DDD分层架构中属于领域层，领域层包含了多个聚合，共同实现核心业务逻辑。聚合内实体以充血模型实现个体业务能力，以及业务逻辑的高内聚。跨多个实体的业务逻辑通过领域服务实现，跨多个聚合的业务逻辑通过应用服务来实现。比如有的业务场景需要同一个聚合的A和B两个实体来共同完成，我们就可以将这段业务逻辑用领域服务来实现，而有的业务逻辑需要通过聚合C和D中的两个服务来实现，那么就用应用服务来组合这两个服务。
聚合根。
班级有班主任，公司有老板，聚合有聚合根。聚合根也叫根实体，他不仅是实体，也是聚合的管理者。如果业务模型中的每个实体都是对等的，任由实体进行无控制的调用和数据修改，很可能导致实体之间数据逻辑的不一致。采用锁的方式会增加软件的复杂度，也会降低系统的性能。聚合根在聚合内部负责协调实体和值对象按照固定的业务规则系统完成共同的业务逻辑。最后在聚合之间，他还是聚合对外的接口人，以聚合根id关联的方式接受外部任务和请求，在上下文内实现聚合之间的业务协同。也就是说，聚合之间通过聚合根id关联引用，如果需要访问其他聚合的实体，就要先访问聚合根，再导航到聚合内部实体，外部对象不能直接访问聚合内实体。
知易行难，理论派的口嗨就到这里了，我们每个开发者能够做的就是心中对代码质量有追求，不断的实践摸索，愿我们都能写出优雅如诗的代码！</description>
    </item>
    
    <item>
      <title>分布式系统一致性和可用性的权衡方法论</title>
      <link>https://hanchao666.top/posts/distributed-system-consistency-avalibility/</link>
      <pubDate>Thu, 12 May 2022 18:25:35 +0800</pubDate>
      
      <guid>https://hanchao666.top/posts/distributed-system-consistency-avalibility/</guid>
      <description>0.理论基础：CAP和BASE CAP理论 理论出处：https://groups.csail.mit.edu/tds/papers/Gilbert/Brewer2.pdf
什么是CAP 指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性）这三个基本需求，最多只能同时满足其中的2个。
一致性：数据在多个副本之间能够保持一致的特性 可用性：系统提供的服务一直处于可用的状态，每次请求都能获得正确的响应。 分区容错性：分布式系统在遇到分区故障的时候，仍然能够对外提供服务。 什么是分区？
在分布式系统中，不同的节点可能分布在不同的机房或子网络中，由于不可避免的故障，例如机器损坏、网络分区等，这些节点之间就会出现无法通信的情况，导致整个系统的环境被分离开来，出现分区。
上面已经提过，在分布式系统中，C、A、P三种特性最多只能选择两种。但这道选择题就像别人在问你“小明的父亲有三个孩子，老大叫大朗，老二叫二郎，请问老三叫什么”一样。在以分布式存系统为限定条件的 CAP 世界里，P 是早已经确定的答案，P 是必须的。
因为，在分布式系统内，P 是必然的发生的，不选 P，一旦发生分区错误，整个分布式系统就完全无法使用了，这是不符合实际需要的。所以，对于分布式系统，我们只能能考虑当发生分区错误时，如何选择一致性和可用性。而根据一致性和可用性的选择不同，开源的分布式系统往往又被分为 CP 系统和 AP 系统。
当一套系统在发生分区故障后，客户端的任何请求都被卡死或者超时，但是，系统的每个节点总是会返回一致的数据，则这套系统就是 CP 系统，经典的比如 Zookeeper。
如果一套系统发生分区故障后，客户端依然可以访问系统，但是获取的数据有的是新的数据，有的还是老数据，那么这套系统就是 AP 系统，经典的比如 Eureka。
用大白话来形容下 CAP ，CAP 就是告诉程序员们当分布式系统出现内部问题了，你要做两种选择：
要么迁就外部服务，像外包公司。 要么让外部服务迁就你，像银行。 迁就外部服务就是我们不能因为我们自己的问题让外部服务的业务运行受到影响，所以要优先可用性。而让外部服务迁就我们，就要优先一致性。所以我们还是要在具体的情景内进行权衡。
BASE理论 BASE 是 Basically Available（基本可用） 、Soft-state（软状态） 和 Eventually Consistent（最终一致性） 三个短语的缩写。
基本可用 什么是基本可用呢？假如系统出现了不可预知故障，允许损失部分可用性，当然也不能完全不可用。
损失的这部分可用性指的是什么？
1.响应时间上的损失 ：正常情况下的搜索引擎0.5秒即返回给用户结果，而基本可用的搜索引擎可以在2秒作用返回结果。
2.功能上的损失 ：在一个电商网站上，正常情况下，用户可以顺利完成每一笔订单。但是到了大促期间，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。
软状态 软状态指允许系统中的数据存在中间状态（CAP 理论中的数据不一致 ），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。
最终一致性 最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。
BASE 理论是对 CAP 中一致性 C 和可用性 A 权衡的结果，其核心思想是：</description>
    </item>
    
    <item>
      <title>单元测试规范</title>
      <link>https://hanchao666.top/posts/unit-test-pricinple/</link>
      <pubDate>Wed, 23 Feb 2022 18:17:18 +0800</pubDate>
      
      <guid>https://hanchao666.top/posts/unit-test-pricinple/</guid>
      <description> 想要成为一名成熟的开发者，就要对自己写过的代码负责。在专业测试介入之前，我们需要通过自测(单元测试 + 接口测试)，来保证程序的基本功能是可以通的，并且单测可以为后续项目代码的修改以及重构提供强有力的质量保证。
单元测试原则
AIR原则，即：
A：Automatic(自动化) I：Independent(独立性) R：Repeatable(可重复) 单元测试目标：语句覆盖率达70%，核心模块的语句覆盖率和分支覆盖率都要达到100%
下面总结如下规范：
提高认知：测试并不是只有测试同学来做，开发一定要完成基本的自测，以便测试同学进行更加专业的测试。不要认为为每个方法增加单测方法并维护是浪费时间的，每个单测可以为方法提供质量保证，是有非常大的收益的。 单测用例之间不能相互调用，也不能依赖执行的先后顺序 单元测试必须全自动执行，禁止人肉参与 必须可重复执行(不能执行一次，测试逻辑就被破坏了) 和数据库相关的单元测试，设定自动回滚机制，不要给数据库造成脏数据；或者给单元测试产生的数据加上明确的前后缀标识作区分。 编写方法代码是要考虑单测方法(分支控制)，使代码变得可测，必要时甚至要对方法进行重构 单测粒度要足够小，至多是类级别，方法级别最好 对于数据库的查询、更新、删除等操作，不能假设数据库的数据是存在的，或者直接操作数据库把数据插入进去，设计用例要逻辑完整，并尽量仿真 核心业务、核心应用、核心模块的增量代码确保单元测试通过，如新增代码，请及时修补单测方法 BCDE原则： B：Border，边界值测试，包括循环边界、特殊取值、特殊时间点、数据顺序等 C：Correct，正确的输入，并得到预期的结果 D：Design，与设计文档相结合，来编写单元测试 E：Error，强制错误信息输入(如：非法数据、异常流程、业务允许外等)，并得到预期的报错结果。 </description>
    </item>
    
  </channel>
</rss>
