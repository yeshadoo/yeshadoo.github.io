<div style="position: fixed; left:5px;max-width:600px; overflow:auto; top: 100px; width: 20vw; bottom:50px">
  <nav id="TableOfContents"></nav>
  </div>
  <head><style type="text/css">::-webkit-scrollbar {
    width: 8px;
    height: 8px;
  }
  ::-webkit-scrollbar-thumb {
    height: 40px;
    background-color: #eee;
    border-radius: 16px;
    &:hover {
      background-color: #ddd;
    }
  }
  </style></head>

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Hugo 0.118.2">

  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="author" content="" />
  <meta property="og:url" content="https://hanchao666.top/posts/why-kafka-niubility/" />
  <link rel="canonical" href="https://hanchao666.top/posts/why-kafka-niubility/" /><link rel="apple-touch-icon" href="/logo.png" />
  <link rel="icon" href="/logo.png" />
  <link rel="shortcut" href="/logo.png" /><link rel="alternate" type="application/atom+xml" href="https://hanchao666.top/index.xml" title="Hadoo&#39;s Blog">

  <script type="application/ld+json">
  {
      "@context" : "http://schema.org",
      "@type" : "BlogPosting",
      "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "https:\/\/hanchao666.top\/"
      },
      "articleSection" : "posts",
      "name" : "Kafka为什么性能这么牛？",
      "headline" : "Kafka为什么性能这么牛？",
      "description" : "Apache Kafka是一个高性能的消息队列，在目前众多消息队列产品中，Kafka的性能绝对是第一梯队的，且Kafka也是大数据生态的组件，背书很硬。下面来看一下，Kafka是如何达到高性能表现的。\n全异步化的线程模型\n简单的说，异步思想就是当我们执行一项比较耗时的操作，不去等待操作结束，而是给这个操作一个命令：当操作完成后，接下来去执行什么。\n使用异步编程模型，虽然不能加快程序本身的速度，但可以减少或者避免线程等待，只用很少的线程就可以达到超高的吞吐能力。异步相对同步，实现的复杂度要更大，代码的可读性和可维护性都会下降，而Kafka作为消息队列，业务逻辑简单并且需要超高的吞吐量，所以场景匹配。\n高性能的异步网络传输\n传统的同步网络IO，一般采用的都是一个线程对应一个Channel接收数据，很难支持高并发和高吞吐量，而异步网络可以用单个线程同时管理多个连接，实现多路复用。\n自定义序列化、反序列化协议\n进程之间通过网络传输结构化数据，需要通过序列化和反序列化来实现结构化数据和二进制数据的双向转换。大多数情况下，选择一个高性能的通用序列化框架都可以满足需求，但是Kafka为了实现超高的性能，自定义了专用的序列化方法，来提高序列化性能，节省传输流量。\n自定义传输协议\n自定义私有应用层传输协议\n批处理\n批处理是一种非常有效的提升系统吞吐量的方法。在Kafka内部，消息都是以批为单位处理的。\nKafka给发送端提供的接口虽然每次只能发送一条消息，但是实际上，Kafka不会立即把这条消息发送出去，而是先在内存中缓存起来，然后选择合适的时机把缓存中的消息组成一批，一次性发给Broker，采用了异步批量发送的机制，攒一波一起发。\n在Kafka的服务端，也就是Broker这一端，不会把一批消息再还原成多条消息一条一条处理，在Broker整个处理流程中，无论是写入磁盘、从磁盘读出来、还是复制到其他副本这些流程中，批消息都不会被解开，一直是作为一条“批消息”来处理。在消费时，消息同样是以批为单位传递，Consumer从Broker拉到一批消息后，在客户端把批消息解开，再一条一条的交给用户代码处理。比如说，你在客户端发送 30 条消息，在业务程序看来，是发送了 30 条消息，而对于 Kafka 的 Broker 来说，它其实就是处理了 1 条包含 30 条消息的“批消息”而已。显然处理 1 次请求要比处理 30 次请求要快得多。\n构建批消息和解开批消息分别在发送端和消费端的客户端完成，不仅减轻了Broker的压力，最重要的是减少了Broker处理请求的次数，提升了总体的处理能力。\n使用顺序读写提升磁盘IO性能\n对于磁盘来说，顺序读写的性能要远远好于随机读写。操作系统每次从磁盘读写数据的是够，需要先寻址，也就是先要找到数据在磁盘上的物理位置，然后再进行数据读写。如果是机械硬盘，这个寻址需要比较长的时间，因为他要移动磁头，这是一个机械运动。顺序读写相比随机读写省去了大部分的寻址时间，它只要寻址一次，就可以连续读写下去，性能要比随机读写好的多。\n在kafka中，对于每个分区，他把从Producer收到的消息，顺序的写入对应的Log文件中，一个文件写满了，就开启一个新的文件这样顺序写下去。消费的时候，也就是从某个全局的位置开始，也就是某一个Log文件中的某个位置开始，顺序的把消息读出来。Kafka充分的利用了顺序读写的这个特性，极大的提升了Kafka在使用磁盘时的IO性能。\n利用PageCache加速消息读写\nPageCache就是操作系统在内存中给磁盘上的文件建立的缓存，在调用系统的API读取文件的时候，并不会直接去读写磁盘上的文件，应用程序实际操作的是PageCache，也就是文件在内存中缓存的副本。\n应用程序在写入文件的时候，操作系统会先把数据写入到内存中的PageCache，然后再一批一批的写到磁盘上。读取文件的时候，也是从PageCache来读取数据，这个时候有两种可能情况。\nPageCache中有数据。直接读取，节省了从磁盘读取数据的时间 PageCache没有数据。操作系统引发缺页中断，应用程序的读取线程会被阻塞，操作系统把数据从文件中复制到PageCache，然后应用程序再从PageCache中继续把数据读出来，这时会进行真正的磁盘IO，读取过程相对较慢。 用户的应用程序在使用完某块PageCache后，操作系统并不会立刻就清除这个PageCache，而是尽可能的利用空闲的物理内存保存这些PageCache，除非系统内存不够用，操作系统才会清掉一部分PageCache，清理策略一般是LRU：优先保留最近一段时间最常使用的那些PageCache。\nKafka在读取消息文件的时候，充分契合了PageCache的特性。一般来说，消息刚刚写到服务端就会被消费，按照LRU的清除策略，读取的时候，对于这种刚刚写入的PageCache，命中的几率会非常高。也就是说，在大部分情况下，消费端读取消息都能命中PageCache，带来的好处有两个：一个一个是读取的速度非常快，另外就是给写入消息让出了磁盘IO资源，间接的提升了写入性能。\n零拷贝技术\n在服务端，处理消息的大致逻辑是这样：\n在文件中找到消息数据，读到内存 把消息通过网络发给客户端 这个过程中，数据会经过两次或者三次复制：\n1.从文件复制数据到PageCache，如果命中PageCache，这一步可以省略。\n2.从PageCache复制到应用程序的内存空间，也就是我们可以操作的对象所在的内存。\n3.从应用程序的内存空间复制到Socket的缓冲区，这个过程就是我们调用网络应用框架的API发送数据的过程。\nKafka使用零拷贝技术可以把这个复制次数减少一次，上面的2、3步骤就可以复制合并成一次复制。直接从PageCache中把数据复制到Socket缓冲区中，这样不仅减少一次数据复制，更重要的是，由于不用把数据复制到用户内存空间，DMA控制器可以直接完成数据复制，不需要CPU参与，速度更快。",
      "inLanguage" : "en-US",
      "author" : "",
      "creator" : "",
      "publisher": "",
      "accountablePerson" : "",
      "copyrightHolder" : "",
      "copyrightYear" : "2022",
      "datePublished": "2022-03-01 18:18:40 \u002b0800 CST",
      "dateModified" : "2022-03-01 18:18:40 \u002b0800 CST",
      "url" : "https:\/\/hanchao666.top\/posts\/why-kafka-niubility\/",
      "keywords" : [  ]
  }
</script>
<title>Kafka为什么性能这么牛？</title>
  <meta property="og:title" content="Kafka为什么性能这么牛？" />
  <meta property="og:type" content="article" />
  <meta property="og:description" content="Apache Kafka是一个高性能的消息队列，在目前众多消息队列产品中，Kafka的性能绝对是第一梯队的，且Kafka也是大数据生态的组件，背书很硬。下面来看一下，Kafka是如何达到高性能表现的。
全异步化的线程模型
简单的说，异步思想就是当我们执行一项比较耗时的操作，不去等待操作结束，而是给这个操作一个命令：当操作完成后，接下来去执行什么。
使用异步编程模型，虽然不能加快程序本身的速度，但可以减少或者避免线程等待，只用很少的线程就可以达到超高的吞吐能力。异步相对同步，实现的复杂度要更大，代码的可读性和可维护性都会下降，而Kafka作为消息队列，业务逻辑简单并且需要超高的吞吐量，所以场景匹配。
高性能的异步网络传输
传统的同步网络IO，一般采用的都是一个线程对应一个Channel接收数据，很难支持高并发和高吞吐量，而异步网络可以用单个线程同时管理多个连接，实现多路复用。
自定义序列化、反序列化协议
进程之间通过网络传输结构化数据，需要通过序列化和反序列化来实现结构化数据和二进制数据的双向转换。大多数情况下，选择一个高性能的通用序列化框架都可以满足需求，但是Kafka为了实现超高的性能，自定义了专用的序列化方法，来提高序列化性能，节省传输流量。
自定义传输协议
自定义私有应用层传输协议
批处理
批处理是一种非常有效的提升系统吞吐量的方法。在Kafka内部，消息都是以批为单位处理的。
Kafka给发送端提供的接口虽然每次只能发送一条消息，但是实际上，Kafka不会立即把这条消息发送出去，而是先在内存中缓存起来，然后选择合适的时机把缓存中的消息组成一批，一次性发给Broker，采用了异步批量发送的机制，攒一波一起发。
在Kafka的服务端，也就是Broker这一端，不会把一批消息再还原成多条消息一条一条处理，在Broker整个处理流程中，无论是写入磁盘、从磁盘读出来、还是复制到其他副本这些流程中，批消息都不会被解开，一直是作为一条“批消息”来处理。在消费时，消息同样是以批为单位传递，Consumer从Broker拉到一批消息后，在客户端把批消息解开，再一条一条的交给用户代码处理。比如说，你在客户端发送 30 条消息，在业务程序看来，是发送了 30 条消息，而对于 Kafka 的 Broker 来说，它其实就是处理了 1 条包含 30 条消息的“批消息”而已。显然处理 1 次请求要比处理 30 次请求要快得多。
构建批消息和解开批消息分别在发送端和消费端的客户端完成，不仅减轻了Broker的压力，最重要的是减少了Broker处理请求的次数，提升了总体的处理能力。
使用顺序读写提升磁盘IO性能
对于磁盘来说，顺序读写的性能要远远好于随机读写。操作系统每次从磁盘读写数据的是够，需要先寻址，也就是先要找到数据在磁盘上的物理位置，然后再进行数据读写。如果是机械硬盘，这个寻址需要比较长的时间，因为他要移动磁头，这是一个机械运动。顺序读写相比随机读写省去了大部分的寻址时间，它只要寻址一次，就可以连续读写下去，性能要比随机读写好的多。
在kafka中，对于每个分区，他把从Producer收到的消息，顺序的写入对应的Log文件中，一个文件写满了，就开启一个新的文件这样顺序写下去。消费的时候，也就是从某个全局的位置开始，也就是某一个Log文件中的某个位置开始，顺序的把消息读出来。Kafka充分的利用了顺序读写的这个特性，极大的提升了Kafka在使用磁盘时的IO性能。
利用PageCache加速消息读写
PageCache就是操作系统在内存中给磁盘上的文件建立的缓存，在调用系统的API读取文件的时候，并不会直接去读写磁盘上的文件，应用程序实际操作的是PageCache，也就是文件在内存中缓存的副本。
应用程序在写入文件的时候，操作系统会先把数据写入到内存中的PageCache，然后再一批一批的写到磁盘上。读取文件的时候，也是从PageCache来读取数据，这个时候有两种可能情况。
PageCache中有数据。直接读取，节省了从磁盘读取数据的时间 PageCache没有数据。操作系统引发缺页中断，应用程序的读取线程会被阻塞，操作系统把数据从文件中复制到PageCache，然后应用程序再从PageCache中继续把数据读出来，这时会进行真正的磁盘IO，读取过程相对较慢。 用户的应用程序在使用完某块PageCache后，操作系统并不会立刻就清除这个PageCache，而是尽可能的利用空闲的物理内存保存这些PageCache，除非系统内存不够用，操作系统才会清掉一部分PageCache，清理策略一般是LRU：优先保留最近一段时间最常使用的那些PageCache。
Kafka在读取消息文件的时候，充分契合了PageCache的特性。一般来说，消息刚刚写到服务端就会被消费，按照LRU的清除策略，读取的时候，对于这种刚刚写入的PageCache，命中的几率会非常高。也就是说，在大部分情况下，消费端读取消息都能命中PageCache，带来的好处有两个：一个一个是读取的速度非常快，另外就是给写入消息让出了磁盘IO资源，间接的提升了写入性能。
零拷贝技术
在服务端，处理消息的大致逻辑是这样：
在文件中找到消息数据，读到内存 把消息通过网络发给客户端 这个过程中，数据会经过两次或者三次复制：
1.从文件复制数据到PageCache，如果命中PageCache，这一步可以省略。
2.从PageCache复制到应用程序的内存空间，也就是我们可以操作的对象所在的内存。
3.从应用程序的内存空间复制到Socket的缓冲区，这个过程就是我们调用网络应用框架的API发送数据的过程。
Kafka使用零拷贝技术可以把这个复制次数减少一次，上面的2、3步骤就可以复制合并成一次复制。直接从PageCache中把数据复制到Socket缓冲区中，这样不仅减少一次数据复制，更重要的是，由于不用把数据复制到用户内存空间，DMA控制器可以直接完成数据复制，不需要CPU参与，速度更快。" />
  <meta name="description" content="Apache Kafka是一个高性能的消息队列，在目前众多消息队列产品中，Kafka的性能绝对是第一梯队的，且Kafka也是大数据生态的组件，背书很硬。下面来看一下，Kafka是如何达到高性能表现的。
全异步化的线程模型
简单的说，异步思想就是当我们执行一项比较耗时的操作，不去等待操作结束，而是给这个操作一个命令：当操作完成后，接下来去执行什么。
使用异步编程模型，虽然不能加快程序本身的速度，但可以减少或者避免线程等待，只用很少的线程就可以达到超高的吞吐能力。异步相对同步，实现的复杂度要更大，代码的可读性和可维护性都会下降，而Kafka作为消息队列，业务逻辑简单并且需要超高的吞吐量，所以场景匹配。
高性能的异步网络传输
传统的同步网络IO，一般采用的都是一个线程对应一个Channel接收数据，很难支持高并发和高吞吐量，而异步网络可以用单个线程同时管理多个连接，实现多路复用。
自定义序列化、反序列化协议
进程之间通过网络传输结构化数据，需要通过序列化和反序列化来实现结构化数据和二进制数据的双向转换。大多数情况下，选择一个高性能的通用序列化框架都可以满足需求，但是Kafka为了实现超高的性能，自定义了专用的序列化方法，来提高序列化性能，节省传输流量。
自定义传输协议
自定义私有应用层传输协议
批处理
批处理是一种非常有效的提升系统吞吐量的方法。在Kafka内部，消息都是以批为单位处理的。
Kafka给发送端提供的接口虽然每次只能发送一条消息，但是实际上，Kafka不会立即把这条消息发送出去，而是先在内存中缓存起来，然后选择合适的时机把缓存中的消息组成一批，一次性发给Broker，采用了异步批量发送的机制，攒一波一起发。
在Kafka的服务端，也就是Broker这一端，不会把一批消息再还原成多条消息一条一条处理，在Broker整个处理流程中，无论是写入磁盘、从磁盘读出来、还是复制到其他副本这些流程中，批消息都不会被解开，一直是作为一条“批消息”来处理。在消费时，消息同样是以批为单位传递，Consumer从Broker拉到一批消息后，在客户端把批消息解开，再一条一条的交给用户代码处理。比如说，你在客户端发送 30 条消息，在业务程序看来，是发送了 30 条消息，而对于 Kafka 的 Broker 来说，它其实就是处理了 1 条包含 30 条消息的“批消息”而已。显然处理 1 次请求要比处理 30 次请求要快得多。
构建批消息和解开批消息分别在发送端和消费端的客户端完成，不仅减轻了Broker的压力，最重要的是减少了Broker处理请求的次数，提升了总体的处理能力。
使用顺序读写提升磁盘IO性能
对于磁盘来说，顺序读写的性能要远远好于随机读写。操作系统每次从磁盘读写数据的是够，需要先寻址，也就是先要找到数据在磁盘上的物理位置，然后再进行数据读写。如果是机械硬盘，这个寻址需要比较长的时间，因为他要移动磁头，这是一个机械运动。顺序读写相比随机读写省去了大部分的寻址时间，它只要寻址一次，就可以连续读写下去，性能要比随机读写好的多。
在kafka中，对于每个分区，他把从Producer收到的消息，顺序的写入对应的Log文件中，一个文件写满了，就开启一个新的文件这样顺序写下去。消费的时候，也就是从某个全局的位置开始，也就是某一个Log文件中的某个位置开始，顺序的把消息读出来。Kafka充分的利用了顺序读写的这个特性，极大的提升了Kafka在使用磁盘时的IO性能。
利用PageCache加速消息读写
PageCache就是操作系统在内存中给磁盘上的文件建立的缓存，在调用系统的API读取文件的时候，并不会直接去读写磁盘上的文件，应用程序实际操作的是PageCache，也就是文件在内存中缓存的副本。
应用程序在写入文件的时候，操作系统会先把数据写入到内存中的PageCache，然后再一批一批的写到磁盘上。读取文件的时候，也是从PageCache来读取数据，这个时候有两种可能情况。
PageCache中有数据。直接读取，节省了从磁盘读取数据的时间 PageCache没有数据。操作系统引发缺页中断，应用程序的读取线程会被阻塞，操作系统把数据从文件中复制到PageCache，然后应用程序再从PageCache中继续把数据读出来，这时会进行真正的磁盘IO，读取过程相对较慢。 用户的应用程序在使用完某块PageCache后，操作系统并不会立刻就清除这个PageCache，而是尽可能的利用空闲的物理内存保存这些PageCache，除非系统内存不够用，操作系统才会清掉一部分PageCache，清理策略一般是LRU：优先保留最近一段时间最常使用的那些PageCache。
Kafka在读取消息文件的时候，充分契合了PageCache的特性。一般来说，消息刚刚写到服务端就会被消费，按照LRU的清除策略，读取的时候，对于这种刚刚写入的PageCache，命中的几率会非常高。也就是说，在大部分情况下，消费端读取消息都能命中PageCache，带来的好处有两个：一个一个是读取的速度非常快，另外就是给写入消息让出了磁盘IO资源，间接的提升了写入性能。
零拷贝技术
在服务端，处理消息的大致逻辑是这样：
在文件中找到消息数据，读到内存 把消息通过网络发给客户端 这个过程中，数据会经过两次或者三次复制：
1.从文件复制数据到PageCache，如果命中PageCache，这一步可以省略。
2.从PageCache复制到应用程序的内存空间，也就是我们可以操作的对象所在的内存。
3.从应用程序的内存空间复制到Socket的缓冲区，这个过程就是我们调用网络应用框架的API发送数据的过程。
Kafka使用零拷贝技术可以把这个复制次数减少一次，上面的2、3步骤就可以复制合并成一次复制。直接从PageCache中把数据复制到Socket缓冲区中，这样不仅减少一次数据复制，更重要的是，由于不用把数据复制到用户内存空间，DMA控制器可以直接完成数据复制，不需要CPU参与，速度更快。" />
  <meta property="og:locale" content="en-us" /><meta property="og:image" content="/logo.png" />
  

  
    <style>body{font-family:bree serif,sans-serif;-webkit-font-smoothing:antialiased;margin:0 20px}article{max-width:800px;margin-left:auto;margin-right:auto}a{color:#000;text-decoration:none}a:hover{font-weight:600;text-decoration:underline}.post-ads{margin:50px 0}.markdown-body{font-size:18px;max-width:100%}.markdown-body a{text-decoration:underline;text-decoration-color:#000}.markdown-body blockquote{margin:0;padding:0 1em;color:#57606a;border-left:.25em solid #d0d7de}.markdown-body pre{padding:16px;overflow:auto;border-radius:10px;background-color:#f6f8fa}.markdown-body code{padding:.2em .4em;font-size:85%;background-color:#f6f8fa;border-radius:6px}.markdown-body pre>code{padding:0;font-size:100%;background-color:inherit;border:0}.Chinese .markdown-body{line-height:200%}.site-date-catalog{font-size:2rem}.header-title{font-size:2rem;font-weight:700;margin-top:32px;font-family:bungee shade,sans-serif}.header-title a{text-decoration:none}.header-subtitle{color:#666}.header-items{margin:10px 0}.header-item{margin:0 5px}.header-line{width:100%;border-width:2px;border-color:#482936;border-style:solid none none none}.lang-switch{font-weight:600}#posts-list{min-height:600px}.posts-line{font-size:1.2rem;margin:12px 0}.posts-categories{font-size:.8rem;margin:auto;text-align:center}.posts-category{padding:3px 0;border:#000 2px solid;border-radius:5px}.site-footer{margin-top:50px}.site-footer-item{margin-right:12px}.post-content img{max-width:100%;display:block;margin-right:auto;margin-top:12px}.post-header{margin-bottom:50px}.post-title{font-size:2rem;font-weight:600}.post-tags{display:inline;font-weight:600;padding:2px 5px;margin-right:6px;border:#000 2px solid;border-radius:5px}.post-date{font-weight:800;font-style:italic}.post-author{float:right;font-weight:600}.page-content{min-height:60%}.post-content{margin-bottom:50px}.post-content p{hyphens:auto;line-height:1.8;text-justify:ideographic;margin-bottom:1em}.related-content{border-width:3px;border-style:solid;border-color:#000;padding:0 10px;margin-bottom:50px;margin-top:100px}.related-content li{margin:5px 0}.taxonomy-term{font-size:3rem}.gallery-img{text-align:center}.gallery-img span{text-align:center}.gallery-img-desc{font-size:.8em;font-weight:800}#disqus_thread{position:relative}#disqus_thread:after{content:"";display:block;height:55px;width:100%;position:absolute;bottom:0;background:#fff}@media screen and (max-width:600px){.header-title,.header-subtitle,.header-items{text-align:center}.posts-line{font-size:16px}.markdown-body{font-size:16px}.post-title{font-size:2rem}.post-content p{letter-spacing:.05em}}@media screen and (max-width:48em){.posts-category{display:none}}</style>
  
  
    <style>.container,.container-fluid{margin-right:auto;margin-left:auto}.container-fluid{padding-right:2rem;padding-left:2rem}.row{box-sizing:border-box;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 1 auto;flex:initial;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:-.5rem;margin-left:-.5rem}.row.reverse{-webkit-box-orient:horizontal;-webkit-box-direction:reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse}.col.reverse{-webkit-box-orient:vertical;-webkit-box-direction:reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse}.col-xs,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9,.col-xs-offset-0,.col-xs-offset-1,.col-xs-offset-10,.col-xs-offset-11,.col-xs-offset-12,.col-xs-offset-2,.col-xs-offset-3,.col-xs-offset-4,.col-xs-offset-5,.col-xs-offset-6,.col-xs-offset-7,.col-xs-offset-8,.col-xs-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-xs{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-xs-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-xs-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-xs-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-xs-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-xs-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-xs-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-xs-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-xs-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-xs-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-xs-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-xs-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-xs-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-xs-offset-0{margin-left:0}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-11{margin-left:91.66666667%}.start-xs{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-xs{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-xs{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-xs{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-xs{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-xs{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-xs{-ms-flex-pack:distribute;justify-content:space-around}.between-xs{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-xs{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-xs{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}@media only screen and (min-width:48em){.container{width:49rem}.col-sm,.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-sm-offset-0,.col-sm-offset-1,.col-sm-offset-10,.col-sm-offset-11,.col-sm-offset-12,.col-sm-offset-2,.col-sm-offset-3,.col-sm-offset-4,.col-sm-offset-5,.col-sm-offset-6,.col-sm-offset-7,.col-sm-offset-8,.col-sm-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-sm{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-sm-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-sm-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-sm-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-sm-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-sm-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-sm-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-sm-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-sm-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-sm-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-sm-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-sm-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-sm-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-sm-offset-0{margin-left:0}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-11{margin-left:91.66666667%}.start-sm{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-sm{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-sm{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-sm{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-sm{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-sm{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-sm{-ms-flex-pack:distribute;justify-content:space-around}.between-sm{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-sm{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-sm{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:64em){.container{width:65rem}.col-md,.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-md-offset-0,.col-md-offset-1,.col-md-offset-10,.col-md-offset-11,.col-md-offset-12,.col-md-offset-2,.col-md-offset-3,.col-md-offset-4,.col-md-offset-5,.col-md-offset-6,.col-md-offset-7,.col-md-offset-8,.col-md-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-md{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-md-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-md-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-md-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-md-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-md-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-md-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-md-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-md-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-md-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-md-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-md-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-md-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-md-offset-0{margin-left:0}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-3{margin-left:25%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-6{margin-left:50%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-9{margin-left:75%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-11{margin-left:91.66666667%}.start-md{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-md{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-md{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-md{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-md{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-md{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-md{-ms-flex-pack:distribute;justify-content:space-around}.between-md{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-md{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-md{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:75em){.container{width:76rem}.col-lg,.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-lg-offset-0,.col-lg-offset-1,.col-lg-offset-10,.col-lg-offset-11,.col-lg-offset-12,.col-lg-offset-2,.col-lg-offset-3,.col-lg-offset-4,.col-lg-offset-5,.col-lg-offset-6,.col-lg-offset-7,.col-lg-offset-8,.col-lg-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-lg{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-lg-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-lg-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-lg-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-lg-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-lg-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-lg-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-lg-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-lg-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-lg-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-lg-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-lg-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-lg-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-lg-offset-0{margin-left:0}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-11{margin-left:91.66666667%}.start-lg{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-lg{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-lg{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-lg{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-lg{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-lg{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-lg{-ms-flex-pack:distribute;justify-content:space-around}.between-lg{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-lg{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-lg{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}</style>
  

  

  <link href="/index.xml" rel="alternate" type="application/rss+xml"
    title="Hadoo&#39;s Blog">
  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Bree+Serif|Bungee+Shade" rel="stylesheet">
  
  

  
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-xxx"></script>
</head>


<body>
  <article class="post " id="article">
    <div class="row">
      <div class="col-xs-12">
        <div class="site-header">
          
<header>
  <div class="header-title">
    <a href="/"
      >Hadoo&#39;s Blog</a
    >
  </div>
  <div class="header-subtitle">大道至简，知行合一</div>
</header>
<div class="row end-md center-xs header-items">
  
  <div class="header-item">
    <a href="https://github.com/yeshadoo" target="_blank">About Me</a>
  </div>
  
  <div class="header-item">
    <a href="https://github.com/yeshadoo" target="_blank">Github</a>
  </div>
  
</div>
<div class="row end-xs">
   
  <div class="lang-switch col-xs-3 col-xs-offset-9">
    <a href="/cn/">Chinese</a>
  </div>
   
</div>
<div class="header-line"></div>

        </div>
        <header class="post-header">
          <h1 class="post-title">Kafka为什么性能这么牛？</h1>
          
          <div class="row post-desc">
            <div class="col-xs-6">
              
              <time class="post-date" datetime="2022-03-01 18:18:40 CST">
                01 Mar 2022
              </time>
              
            </div>
            <div class="col-xs-6">
              
            </div>
          </div>
          
        </header>

        <div class="post-content markdown-body">
          
          <p>Apache Kafka是一个高性能的消息队列，在目前众多消息队列产品中，Kafka的性能绝对是第一梯队的，且Kafka也是大数据生态的组件，背书很硬。下面来看一下，Kafka是如何达到高性能表现的。</p>
<blockquote>
<p>全异步化的线程模型</p>
</blockquote>
<p>简单的说，异步思想就是当我们执行一项比较耗时的操作，不去等待操作结束，而是给这个操作一个命令：当操作完成后，接下来去执行什么。</p>
<p>使用异步编程模型，虽然不能加快程序本身的速度，但可以减少或者避免线程等待，只用很少的线程就可以达到超高的吞吐能力。异步相对同步，实现的复杂度要更大，代码的可读性和可维护性都会下降，而Kafka作为消息队列，业务逻辑简单并且需要超高的吞吐量，所以场景匹配。</p>
<blockquote>
<p>高性能的异步网络传输</p>
</blockquote>
<p>传统的同步网络IO，一般采用的都是一个线程对应一个Channel接收数据，很难支持高并发和高吞吐量，而异步网络可以用单个线程同时管理多个连接，实现多路复用。</p>
<blockquote>
<p>自定义序列化、反序列化协议</p>
</blockquote>
<p>进程之间通过网络传输结构化数据，需要通过序列化和反序列化来实现结构化数据和二进制数据的双向转换。大多数情况下，选择一个高性能的通用序列化框架都可以满足需求，但是Kafka为了实现超高的性能，自定义了专用的序列化方法，来提高序列化性能，节省传输流量。</p>
<blockquote>
<p>自定义传输协议</p>
</blockquote>
<p>自定义私有应用层传输协议</p>
<blockquote>
<p>批处理</p>
</blockquote>
<p>批处理是一种非常有效的提升系统吞吐量的方法。在Kafka内部，消息都是以批为单位处理的。</p>
<p>Kafka给发送端提供的接口虽然每次只能发送一条消息，但是实际上，Kafka不会立即把这条消息发送出去，而是先在内存中缓存起来，然后选择合适的时机把缓存中的消息组成一批，一次性发给Broker，采用了异步批量发送的机制，攒一波一起发。</p>
<p>在Kafka的服务端，也就是Broker这一端，不会把一批消息再还原成多条消息一条一条处理，在Broker整个处理流程中，无论是写入磁盘、从磁盘读出来、还是复制到其他副本这些流程中，批消息都不会被解开，一直是作为一条“批消息”来处理。在消费时，消息同样是以批为单位传递，Consumer从Broker拉到一批消息后，在客户端把批消息解开，再一条一条的交给用户代码处理。比如说，你在客户端发送 30 条消息，在业务程序看来，是发送了 30 条消息，而对于 Kafka 的 Broker 来说，它其实就是处理了 1 条包含 30 条消息的“批消息”而已。显然处理 1 次请求要比处理 30 次请求要快得多。</p>
<p>构建批消息和解开批消息分别在发送端和消费端的客户端完成，不仅减轻了Broker的压力，最重要的是减少了Broker处理请求的次数，提升了总体的处理能力。</p>
<blockquote>
<p>使用顺序读写提升磁盘IO性能</p>
</blockquote>
<p>对于磁盘来说，顺序读写的性能要远远好于随机读写。操作系统每次从磁盘读写数据的是够，需要先寻址，也就是先要找到数据在磁盘上的物理位置，然后再进行数据读写。如果是机械硬盘，这个寻址需要比较长的时间，因为他要移动磁头，这是一个机械运动。顺序读写相比随机读写省去了大部分的寻址时间，它只要寻址一次，就可以连续读写下去，性能要比随机读写好的多。</p>
<p>在kafka中，对于每个分区，他把从Producer收到的消息，顺序的写入对应的Log文件中，一个文件写满了，就开启一个新的文件这样顺序写下去。消费的时候，也就是从某个全局的位置开始，也就是某一个Log文件中的某个位置开始，顺序的把消息读出来。Kafka充分的利用了顺序读写的这个特性，极大的提升了Kafka在使用磁盘时的IO性能。</p>
<blockquote>
<p>利用PageCache加速消息读写</p>
</blockquote>
<p>PageCache就是操作系统在内存中给磁盘上的文件建立的缓存，在调用系统的API读取文件的时候，并不会直接去读写磁盘上的文件，应用程序实际操作的是PageCache，也就是文件在内存中缓存的副本。</p>
<p>应用程序在写入文件的时候，操作系统会先把数据写入到内存中的PageCache，然后再一批一批的写到磁盘上。读取文件的时候，也是从PageCache来读取数据，这个时候有两种可能情况。</p>
<ul>
<li>PageCache中有数据。直接读取，节省了从磁盘读取数据的时间</li>
<li>PageCache没有数据。操作系统引发缺页中断，应用程序的读取线程会被阻塞，操作系统把数据从文件中复制到PageCache，然后应用程序再从PageCache中继续把数据读出来，这时会进行真正的磁盘IO，读取过程相对较慢。</li>
</ul>
<p>用户的应用程序在使用完某块PageCache后，操作系统并不会立刻就清除这个PageCache，而是尽可能的利用空闲的物理内存保存这些PageCache，除非系统内存不够用，操作系统才会清掉一部分PageCache，清理策略一般是LRU：优先保留最近一段时间最常使用的那些PageCache。</p>
<p>Kafka在读取消息文件的时候，充分契合了PageCache的特性。一般来说，消息刚刚写到服务端就会被消费，按照LRU的清除策略，读取的时候，对于这种刚刚写入的PageCache，命中的几率会非常高。也就是说，在大部分情况下，消费端读取消息都能命中PageCache，带来的好处有两个：一个一个是读取的速度非常快，另外就是给写入消息让出了磁盘IO资源，间接的提升了写入性能。</p>
<blockquote>
<p>零拷贝技术</p>
</blockquote>
<p>在服务端，处理消息的大致逻辑是这样：</p>
<ul>
<li>在文件中找到消息数据，读到内存</li>
<li>把消息通过网络发给客户端</li>
</ul>
<p>这个过程中，数据会经过两次或者三次复制：</p>
<p>1.从文件复制数据到PageCache，如果命中PageCache，这一步可以省略。</p>
<p>2.从PageCache复制到应用程序的内存空间，也就是我们可以操作的对象所在的内存。</p>
<p>3.从应用程序的内存空间复制到Socket的缓冲区，这个过程就是我们调用网络应用框架的API发送数据的过程。</p>
<p>Kafka使用零拷贝技术可以把这个复制次数减少一次，上面的2、3步骤就可以复制合并成一次复制。直接从PageCache中把数据复制到Socket缓冲区中，这样不仅减少一次数据复制，更重要的是，由于不用把数据复制到用户内存空间，DMA控制器可以直接完成数据复制，不需要CPU参与，速度更快。</p>

        </div>

        <div class="row middle-xs">
          <div class="col-xs-12">
            
          </div>
        </div>
        
          <div class="row">
            <div class="col-xs-12">
              <br/><br/><p>Subscribe：<a target="_blank" href="https://mailchi.mp/a1a0d59e7a19/hadoo"><b>Mailchimp</b></a></p><br/><a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://blog.joway.io/images/cc.png" /></a>
            </div>
          </div>

          



          
          
          <div style="height: 50px;"></div>
          
        

        <div class="site-footer">
  
  
</div>

      </div>
    </div>
  </article>

  
<script src="/js/lazyload.min.js"></script>
<script>
  var lazyImage = new LazyLoad({
    container: document.getElementById('article')
  });
</script>

<script>
  
  
    
    
  
</script>

  

</body>

</html>